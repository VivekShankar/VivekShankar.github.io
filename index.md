<h1 align="center"> Backgroundasdf </h1>

RainCheck is an initiative to develop smartphones whose touchscreens function well even in the presence of water on the touchscreens: when it is raining, or our fingers are wet. Most modern smartphones use a grid of capacitive sensors to detect touches on the screen.

<img src="http://www.iphoneinformer.com/wp-content/uploads/2015/11/wet-iPhone-6-2.jpg" alt="Monkey" style="width:332px;height:164px;" align="right">

Capacitive means the sensors have the ability to absorb, or store electrons. When you touch a capacitive touchscreen with your finger, you cause a change in the screen’s electrical field – a change in the capacitance values of the region of the screen you touched. Fingers are capacitive, which is why touchscreens work so well with our fingers, but so too are water droplets. Thus, the major challenge of making the touchscreen robust to water droplets is the fact that water droplets change the capacitance of electrodes on the screen in a similar way to a user’s fingers. The touchscreen gets confused between water droplets and our fingers, and irregularly registers “false touches” at different points on the screen due to the presence of water.

My mentor is [Professor Mayank Goel](https://www.hcii.cmu.edu/people/mayank-goel), Assistant Professor in the Institute of Software Research and the Human Computer Interaction Institute.For more information on past work done on the RainCheck project, check out the official RainCheck project [site](https://ubicomplab.github.io/RainCheck/index.html). You can also view my entire project proposal [here](https://github.com/VivekShankar/VivekShankar.github.io/blob/master/15400ProjectProposalFinal.pdf).

<h1 align="center"> Timeline </h1>

| Week  | Milestone | Link |
| ---  | ---  | ---  | 
| Dec. 16  | Understand background material and learn technologies. | [Report](https://github.com/VivekShankar/VivekShankar.github.io/blob/master/MilestoneReport1.pdf) | 
| Feb. 13  | Finalize design and logistical details of the experiment to collect data on different user interactions when the phone is wet. | N/A | 
| Feb. 27  | Start evaluating the results of the Machine Learning models for distinguishing between real, finger-based and false, water-induced touches in a controlled setting. Start addressing the problem of touch-typing in the presence of water. Work on the first approach: constructing the real touch-typing path from the incorrect path recorded by the phone. | N/A | 
| Mar. 20  | Finish evaluating the results of the Machine Learning models in a controlled setting. Continue work on user touch-typing. Work on the second approach: construct the real message typed by the user from the incorrect message the phone recorded. | N/A | 
| Apr. 3  | Finish work on enabling the algorithms to run in real-time. Evaluate the results of the new Machine Learning models developed for use in real-time. Begin work on the research poster and paper for the Meeting of the Minds project report. | N/A | 
| Apr. 17  | Finish work on touch typing in the presence of water. Evaluate the results of the Machine Learning models developed for touch typing. Continue work on the research poster and paper. | N/A | 
| May 1  | Finish the research poster and the written report. | N/A | 
